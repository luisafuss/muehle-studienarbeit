{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Muehle_Logic.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Muehle_Utilities.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Muehle_Heuristik.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memoize(f):\n",
    "    global Cache\n",
    "    \n",
    "    def f_memoized(*args):\n",
    "        key = (args[0], args[1])\n",
    "        if key in Cache:\n",
    "            return Cache[key]\n",
    "        result = f(*args)\n",
    "        Cache[key] = result\n",
    "        return result\n",
    "    \n",
    "    return f_memoized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax-Algorithmus\n",
    "\n",
    "Der Minimax-Algorithmus wird im Rahmen dieser Studienarbeit für die Ermittlung der optimalen Strategie für das Nulsummenspiel Mühle verwendet. \n",
    "Prinzip. Dabei ist der Minimax-Algorithmus ist ein relativ einfacher Algorithmus, der durch die Verwendung von Alpha-Beta-Pruning deutlich verbessert wird.\n",
    "\n",
    "Der Minimax-Algorithmus beruht auf einer Bewertungsfunktion und systematischer Suche. Gundlegend werden bei Minimax alle auf den Aktuellen Spielstatus folgenden Zustände berechnet und bewertet. Dies ist vergleichbar mit einer Baumstruktur, bei der bis zu den Blättern alle Zustände ausgewertet werden. Da dies aus Gründen der Rechenzeit und des Speichers nicht möglich ist, werden die Folgezustände nur bis zu einer gewissen Tiefe berechnet und ausgewertet. Um nur bis zu einer geringen Baumtiefe suchen zu können wird allerdings eine geeignete Heuristik benötigt. Mit der Nutzung dieser Heuristik verlieren wir allerdings die Sicherheit den optimalen Zug zu wählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion `value_minimax(State, player)` erhält drei Argumente. Einen Spielzustand, einen Spieler und die Suchtiefe. Die Funktion gibt dabei den Wert zurück, den dieser Status für den übergeben Spieler hat.\n",
    "Dieser Wert Wert wird, für den Fall, dass das Spiel mit dem übergebenen Zustand beendet ist von def Funktion `finished()` berechnet. Wenn die maximale Suchtiefe erreicht wurde wird der Wert allerdings von der Funktion `heuristic()` berechnet.\n",
    "Ist die maximale Suchtiefe noch nicht erreicht wird rekursiv nach dem besten Folgezustand gesucht.\n",
    "Um Werte für Zustände nicht mehrfach berechnen zu müssen werden diese duch Memoisation `@memoize` zwischengespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoize\n",
    "def value_minimax(state, player, depth):\n",
    "    if finished(to_list(state)):\n",
    "        return utility(to_list(state), player)\n",
    "    if depth == 0:\n",
    "        return heuristic(state, player)\n",
    "    o = opponent(player)\n",
    "    depth -= 1\n",
    "    return max([ -value_minimax(to_tuple(ns), o, depth) for ns in next_states(to_list(state), player) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion `best_move_minimax(State, player)` erhält drei Argumente. Einen SPielzustand, einen Spieler und die Suchtiefe. Die Rügkabewerte sind der von der Funktion ermittelte beste Folgezustand und dessen Bewertung. Gibt es mehrere beste Folgezustände wird der Folgezustand zufällig ausgewählt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_move_minimax(state, player, depth):\n",
    "    ns          = next_states(state, player)\n",
    "    best_value  = value_minimax(to_tuple(state), player, depth)\n",
    "    best_moves  = [s for s in ns if -value_minimax(to_tuple(s), opponent(player), depth - 1 ) == best_value]\n",
    "    best_state  = random.choice(best_moves)\n",
    "    return best_value, best_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion minimax(State, Player) wurde erstellt, um die Funktion best_move_minimax(State, player) nach Außen eindeutiger von alpha_beta_pruning(State, Player) abzugrenzen. Die übergebenen Argumente und Rückgabewerte entsprechen somit denen der Funktion best_move_minimax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(state, player, depth = 5):\n",
    "    return(best_move_minimax(state, player, depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha-Beta-Pruning\n",
    "Das Alpha-Beta-Pruning ist, wie im Rahmen des Minimax-Algorithmus schon erwähnt eine Verbesserung von Minimax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cache = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`value_ab(State, player, alpha=-1, beta=1)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_ab(state, player, alpha=-1, beta=1, depth = 6):\n",
    "    global Cache\n",
    "    state = to_tuple(state)\n",
    "    if state in Cache:\n",
    "        value, a, b = Cache[state]\n",
    "        if a <= alpha and beta <= b:\n",
    "            return value\n",
    "        else:\n",
    "            alpha = min(alpha, a)\n",
    "            beta  = max(beta , b)\n",
    "            value   = alphaBeta(state, player, alpha, beta, depth=depth)\n",
    "            Cache[state] = value, alpha, beta\n",
    "            return value\n",
    "    else:\n",
    "        value = alphaBeta(state, player, alpha, beta, depth=depth)\n",
    "        Cache[state] = value, alpha, beta\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`alphaBeta(State, player, alpha, beta)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphaBeta(state, player, alpha, beta, depth):\n",
    "    state = to_list(state)\n",
    "    if finished(state):\n",
    "        return utility(state, player)\n",
    "    if depth == 0:\n",
    "        return heuristic(state, player)\n",
    "    value = alpha\n",
    "    for ns in next_states(state, player):\n",
    "        value = max(value, -value_ab(ns, opponent(player), -beta, -alpha, depth = depth-1))\n",
    "        if value >= beta:\n",
    "            return value\n",
    "        alpha = max(value, alpha)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_move_ab(state, player, depth = 6):\n",
    "    ns         = next_states(state, player)\n",
    "    moves = [(-value_ab(s, opponent(player), depth), s) for s in ns]\n",
    "    (best_value, best_state) = max(moves, key=lambda x:x[0])\n",
    "    return best_value, best_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion `alpha_beta_pruning(State, Player)` wurde erstellt, um die Funktion `best_move(State, player)` nach Außen eindeutiger von `minimax(State, Player)` abzugrenzen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_beta_pruning(state, player, depth = 6):\n",
    "    return(best_move_ab(state, player, depth = depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktionstests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time\n",
    "#start = time.time()\n",
    "#state = [[4, 5], [[0, 2, 0, 0, 2, 0, 0, 0], [2, 1, 1, 0, 0, 0, 0, 0], [2, 1, 1, 1, 0, 0, 0, 0]]]\n",
    "#print(alpha_beta_pruning(state, 2, 5))\n",
    "#end = time.time()\n",
    "#print(str(end-start)+'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time\n",
    "#start = time.time()\n",
    "#state = [[4, 5], [[0, 2, 0, 0, 2, 0, 0, 0], [2, 1, 1, 0, 0, 0, 0, 0], [2, 1, 1, 1, 0, 0, 0, 0]]]\n",
    "#print(minimax(state, 2, 5))\n",
    "#end = time.time()\n",
    "#print(str(end-start)+'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time\n",
    "#start = time.time()\n",
    "#state = [[5, 6], [[0, 0, 0, 2, 0, 0, 0, 0], [0, 1, 1, 1, 2, 0, 2, 0], [0, 1, 0, 0, 0, 0, 0, 0]]]\n",
    "#print(alpha_beta_pruning(state, 2, 5))\n",
    "#end = time.time()\n",
    "#print(str(end-start)+'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}